{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these boxes are heavy duty (for the pc) and some of these are just light enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': \"Ito'y isang trabaho para sa akin.\"}]\n"
     ]
    }
   ],
   "source": [
    "# machine translation; USE THE PC FOR THIS\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-tl\")\n",
    "\n",
    "print(pipe(\"This is a job for me.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ang_Bangka_ni_Tatay_Mario___Filipino-v12023.04.12T012033.epub', 'Ang_Paglalaro_nina_Mina_at_Manay___Filipino-v12023.06.16T022744.epub', 'Ano_ang_Kinatatakutan_nina__Anopol_at_ni_Tang-id___Filipino-v12023.06.20T194135.epub', 'Luna_Papelastika___Filipino-v12023.04.07T035616.epub', 'Misteryo_ng_Itlog___Filipino.epub', 'Pwedeng-pwede,_Pani!___Filipino-v12023.04.07T033002.epub', 'Sino_ang_Magiging_Titser_Ko_sa_Pasukan____Filipino-v12023.11.14T034013.epub', 'Si_Kokoy_at_ang_Umang-umang___Filipino-v12023.04.07T084156.epub', 'Si_Pogi,_Si_Pogs_At_Ang_Tora-tora___Filipino-v12023.11.14T082955.epub', 'Super_Wanda___Filipino-v12023.04.07T025901.epub']\n"
     ]
    }
   ],
   "source": [
    "import tika\n",
    "from tika import parser\n",
    "import os\n",
    "\n",
    "print(os.listdir(\"./booksEpub\"))\n",
    "\n",
    "epubList = []\n",
    "\n",
    "for i in os.listdir(\"./booksEpub\"):\n",
    "    filePath = \"./booksEpub/\" + i\n",
    "    epubList.append(parser.from_file(filePath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "import os\n",
    "\n",
    "print(os.listdir(\"./booksEpub\"))\n",
    "\n",
    "ebookContent = {}\n",
    "\n",
    "for i in os.listdir(\"./booksEpub\"):\n",
    "    ebookText = \"\"\n",
    "    titlePageText = \"\"\n",
    "    filePath = \"./booksEpub/\" + i\n",
    "    doc = pymupdf.open(filePath)\n",
    "    for chapter in range(doc.chapter_count):\n",
    "        print(f\"Chapter {chapter}\")\n",
    "        if chapter==0:\n",
    "            # get the texts and it will be the key\n",
    "            currentPage = doc[(0,0)]\n",
    "            titlePageText = currentPage.get_text()\n",
    "        else:\n",
    "            for page in range(doc.chapter_page_count(chapter)):\n",
    "                print(f\"page {page}\")\n",
    "                currentPage = doc[(chapter, page)]\n",
    "                currentText = currentPage.get_text()\n",
    "                print(currentText)\n",
    "                # check if it's the last few pages\n",
    "                if not((\"Brought to you by\" in currentText) or (\"International License\" in currentText) or (\"Table of Contents\" in currentText) or (\"This book was developed as part of the ABC\" in currentText) or (\"Advancing Basic Education in the Philippines\" in currentText)):\n",
    "                    ebookText+=currentText\n",
    "                else:\n",
    "                    pass\n",
    "    \n",
    "    #print(ebookText)\n",
    "    ebookContent[titlePageText] = ebookText\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for key in ebookContent.keys():\n",
    "    print(key)\n",
    "    processedKey = re.sub(r'[\\.]','',key)\n",
    "    processedKey = re.sub(r' ','_',processedKey)\n",
    "    processedKey = re.sub(r'\\?','',processedKey)\n",
    "    processedKey = re.sub(r'\\n','_',processedKey)\n",
    "    f = open(f\"./textData1_pymupdf/{processedKey}.txt\",\"w\",encoding='utf-8')\n",
    "    #print(ebookContent[key])\n",
    "    f.writelines(ebookContent[key])\n",
    "    f.close()\n",
    "    #print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "sourceFolder = \"./textData1_pymupdf\"\n",
    "\n",
    "totalText = \"\"\n",
    "\n",
    "# format the text correctly first\n",
    "for i in os.listdir(sourceFolder):\n",
    "    filePathForTokenizingText = f\"{sourceFolder}/{i}\"\n",
    "    f = open(filePathForTokenizingText,'r', encoding='utf-8')\n",
    "    insideText = f.read()\n",
    "    f.close()\n",
    "\n",
    "    #formatting with regex\n",
    "\n",
    "    insideText = re.sub(r'[.]','. ',insideText)\n",
    "    insideText = re.sub('\\n',' ',insideText)\n",
    "    insideText = re.sub('- ','-',insideText)\n",
    "    insideText = re.sub('  ',' ',insideText)\n",
    "    insideText = re.sub('&nbsp;','',insideText)\n",
    "\n",
    "    totalText += insideText\n",
    "    totalText += \"\\n\\n\"\n",
    "\n",
    "f2 = open(\"./textData_forTokenization/textAll.txt\", \"w\", encoding='utf-8')\n",
    "f2.writelines(totalText)\n",
    "f2.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131162"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# organize it properly\n",
    "import re\n",
    "\n",
    "tagged_Text = open(\"./textData_postagged/textAll_tagged.txt\", 'r', encoding=\"utf-16\")\n",
    "\n",
    "allText = tagged_Text.read()\n",
    "#print(allText)\n",
    "allText = re.sub(r'\\|PMP \\\"\\|PMS\\n', '|PMP  \\n\\\"|PMS ', allText)\n",
    "allText = re.sub(r'\\|PMQ \\\"\\|PMS\\n', '|PMQ  \\n\\\"|PMS ', allText)\n",
    "allText = re.sub(r'\\|PME \\\"\\|PMS\\n', '|PME  \\n\\\"|PMS ', allText)\n",
    "allText = re.sub(r'\\|PMS \\\"\\|PMS\\n', '|PMS  \\n\\\"|PMS ', allText)\n",
    "allText = re.sub(r'\\|PMC \\\"\\|PMS\\n', '|PMC  \\n\\\"|PMS ', allText)\n",
    "allText = re.sub(r'\\|PMSC \\\"\\|PMS\\n','|PMSC \\n\\\"|PMS ', allText)\n",
    "\n",
    "#print(allText)\n",
    "\n",
    "final_Text = open(\"./textData_postagged/textAll_tagged_final.txt\", 'w')\n",
    "final_Text.write(allText)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "making the vocabulary and the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "postagged_filepath = \"./textData_postagged/textAll_tagged_final.txt\"\n",
    "\n",
    "vocabulary = set()\n",
    "\n",
    "f = open(f\"{postagged_filepath}\", \"r\", encoding=\"utf-8\")\n",
    "story = f.read()\n",
    "    \n",
    "for sentence in story.split('\\n'):\n",
    "    for token in sentence.split(' '):\n",
    "        vocabulary.add(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "vocabulary_F = vocabulary.remove('')\n",
    "\n",
    "vocab_df = pd.DataFrame(list(vocabulary), columns=['tokens'])\n",
    "vocab_df['lemma'] = vocab_df['tokens'].apply(lambda x: x.split('|')[0])\n",
    "vocab_df['postag'] = vocab_df['tokens'].apply(lambda x: x.split('|')[1])\n",
    "vocab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(618,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                kapatid|NNC\n",
       "2               simangot|NNC\n",
       "6                pintuan|NNC\n",
       "11                  baso|NNC\n",
       "16                  usok|NNC\n",
       "20               kutsara|NNC\n",
       "24               krayola|NNC\n",
       "25               paligid|NNC\n",
       "29                bulong|NNC\n",
       "30                 bunga|NNC\n",
       "34              paghinga|NNC\n",
       "44                lupain|NNC\n",
       "45                    Pa|NNC\n",
       "52                balita|NNC\n",
       "59               sandali|NNC\n",
       "62               balyena|NNC\n",
       "66              senyales|NNC\n",
       "67                 grado|NNC\n",
       "71                 tanim|NNC\n",
       "75                  ulap|NNC\n",
       "86                kusina|NNC\n",
       "90              meryenda|NNC\n",
       "91                 niyog|NNC\n",
       "99                 plano|NNC\n",
       "103               kamote|NNC\n",
       "104                baboy|NNC\n",
       "115                dahan|NNC\n",
       "116                basag|NNC\n",
       "119             kamoteng|NNC\n",
       "122             kaharian|NNC\n",
       "135               tanong|NNC\n",
       "139               aalala|NNC\n",
       "147               tansan|NNC\n",
       "153               regalo|NNC\n",
       "154                 alis|NNC\n",
       "157                 misa|NNC\n",
       "164                 akda|NNC\n",
       "166                 lobo|NNC\n",
       "167                lipad|NNC\n",
       "182          papelastika|NNC\n",
       "191                lugar|NNC\n",
       "197              talisay|NNC\n",
       "198                pares|NNC\n",
       "199                 imik|NNC\n",
       "200               presyo|NNC\n",
       "204                 sabi|NNC\n",
       "211                laing|NNC\n",
       "215                babae|NNC\n",
       "217                tawag|NNC\n",
       "218                 aaya|NNC\n",
       "226                tribo|NNC\n",
       "227                saliw|NNC\n",
       "234               ibabaw|NNC\n",
       "235               kalaro|NNC\n",
       "237                ideya|NNC\n",
       "248            panaginip|NNC\n",
       "250                 ilaw|NNC\n",
       "252            restawran|NNC\n",
       "253                kahon|NNC\n",
       "255             paibabaw|NNC\n",
       "259            karagatan|NNC\n",
       "269                hamon|NNC\n",
       "270                 sako|NNC\n",
       "272                ingay|NNC\n",
       "277              pamilya|NNC\n",
       "281                gamit|NNC\n",
       "284                parte|NNC\n",
       "285              talunan|NNC\n",
       "290              sibuyas|NNC\n",
       "294                papel|NNC\n",
       "301                 iyak|NNC\n",
       "308               tingin|NNC\n",
       "312                bayan|NNC\n",
       "317               usupan|NNC\n",
       "321              tirahan|NNC\n",
       "323                 agos|NNC\n",
       "328          pangingisda|NNC\n",
       "335             chainsaw|NNC\n",
       "340                buhos|NNC\n",
       "342               dibdib|NNC\n",
       "344               bilang|NNC\n",
       "346            kalagayan|NNC\n",
       "349                 alab|NNC\n",
       "352             sampalok|NNC\n",
       "357             paborito|NNC\n",
       "361                lilim|NNC\n",
       "362                 Kuya|NNC\n",
       "365               hangin|NNC\n",
       "366                 kape|NNC\n",
       "374          eskuwelahan|NNC\n",
       "386                bigas|NNC\n",
       "388              bintana|NNC\n",
       "390                 sala|NNC\n",
       "391                 luha|NNC\n",
       "393          kasangkapan|NNC\n",
       "401                  tao|NNC\n",
       "407                  mam|NNC\n",
       "408                hugis|NNC\n",
       "415               teksto|NNC\n",
       "416                  asa|NNC\n",
       "417              sinulid|NNC\n",
       "421                 laki|NNC\n",
       "422                dilim|NNC\n",
       "425             tindahan|NNC\n",
       "429                 kama|NNC\n",
       "433                hinay|NNC\n",
       "441               kidlat|NNC\n",
       "443               kwento|NNC\n",
       "446                 Diba|NNC\n",
       "447           Sumimangot|NNC\n",
       "453                kagat|NNC\n",
       "455              pinsala|NNC\n",
       "459               pagong|NNC\n",
       "460                 suka|NNC\n",
       "461          pagbabahagi|NNC\n",
       "470            kalamansi|NNC\n",
       "474                likod|NNC\n",
       "478                uling|NNC\n",
       "493                 Isda|NNC\n",
       "497           halakhakan|NNC\n",
       "498             kuryente|NNC\n",
       "503             eroplano|NNC\n",
       "505                butil|NNC\n",
       "509                dagat|NNC\n",
       "512                alaga|NNC\n",
       "514                  opo|NNC\n",
       "519     pagtatarabahuhan|NNC\n",
       "522               pigura|NNC\n",
       "524               pisara|NNC\n",
       "527             pagbukas|NNC\n",
       "532               gulong|NNC\n",
       "542              kalaban|NNC\n",
       "550               hardin|NNC\n",
       "559              alukaba|NNC\n",
       "563              pasilyo|NNC\n",
       "564             pagputok|NNC\n",
       "568                sahig|NNC\n",
       "570                 Mama|NNC\n",
       "572               pating|NNC\n",
       "573          kapahamakan|NNC\n",
       "583              tabagak|NNC\n",
       "585                 keso|NNC\n",
       "591              katawan|NNC\n",
       "593                 haba|NNC\n",
       "596             kumidlat|NNC\n",
       "601           pagkakaiba|NNC\n",
       "614                buhay|NNC\n",
       "619          pamamagitan|NNC\n",
       "625            bisikleta|NNC\n",
       "630                mundo|NNC\n",
       "631                tanda|NNC\n",
       "632              paninda|NNC\n",
       "634                tugon|NNC\n",
       "641                 maya|NNC\n",
       "644                talon|NNC\n",
       "650                grupo|NNC\n",
       "654                aayos|NNC\n",
       "655                kahoy|NNC\n",
       "660              tularan|NNC\n",
       "664                 toyo|NNC\n",
       "666         ikinabubuhay|NNC\n",
       "674                kasya|NNC\n",
       "675              galamay|NNC\n",
       "677                 dali|NNC\n",
       "684                ganda|NNC\n",
       "688           pagmamahal|NNC\n",
       "701                elesi|NNC\n",
       "706              klasrum|NNC\n",
       "710              lungsod|NNC\n",
       "712                 lupa|NNC\n",
       "726        kapangyarihan|NNC\n",
       "727                  Dun|NNC\n",
       "728              butones|NNC\n",
       "736           panghuhuli|NNC\n",
       "740              pagkain|NNC\n",
       "746                 kwak|NNC\n",
       "748                tigil|NNC\n",
       "752           papelastik|NNC\n",
       "755                 sari|NNC\n",
       "756                kaisa|NNC\n",
       "760                 alon|NNC\n",
       "762                 gabi|NNC\n",
       "768               gawain|NNC\n",
       "769            mamingwit|NNC\n",
       "770            pahiwatig|NNC\n",
       "773                patak|NNC\n",
       "775                 ahas|NNC\n",
       "777           kabundukan|NNC\n",
       "788              liwanag|NNC\n",
       "792            paglangoy|NNC\n",
       "796           pagdrowing|NNC\n",
       "799                 susi|NNC\n",
       "803                 puso|NNC\n",
       "816                 taas|NNC\n",
       "817             Sumagang|NNC\n",
       "822              katribo|NNC\n",
       "831             pagtawag|NNC\n",
       "832                 sapa|NNC\n",
       "836             panangga|NNC\n",
       "837          nakatatanda|NNC\n",
       "847                 damo|NNC\n",
       "859                kanin|NNC\n",
       "866            managinip|NNC\n",
       "867              balikat|NNC\n",
       "870               itsura|NNC\n",
       "878             paaralan|NNC\n",
       "883                 kaba|NNC\n",
       "885                   Aw|NNC\n",
       "896              pagsang|NNC\n",
       "902                Sayaw|NNC\n",
       "907             kaingero|NNC\n",
       "908                hapon|NNC\n",
       "909                batik|NNC\n",
       "912            pamumuhay|NNC\n",
       "916                kurap|NNC\n",
       "918                beses|NNC\n",
       "928                bagay|NNC\n",
       "929          mangingisda|NNC\n",
       "930                 taon|NNC\n",
       "933               bituin|NNC\n",
       "938             pangalan|NNC\n",
       "941               pugita|NNC\n",
       "943                tunog|NNC\n",
       "946               paalam|NNC\n",
       "949               siyato|NNC\n",
       "952            karanasan|NNC\n",
       "957                itlog|NNC\n",
       "961            paglampas|NNC\n",
       "963          Dumadausdos|NNC\n",
       "968             alimasag|NNC\n",
       "970                 kita|NNC\n",
       "982              insekto|NNC\n",
       "988              papasok|NNC\n",
       "1002                baha|NNC\n",
       "1010                kuha|NNC\n",
       "1011                nigo|NNC\n",
       "1013              binata|NNC\n",
       "1015             tahanan|NNC\n",
       "1021            alikabok|NNC\n",
       "1023             kalsada|NNC\n",
       "1025                mama|NNC\n",
       "1029              korona|NNC\n",
       "1041                 Mam|NNC\n",
       "1045           kabahayan|NNC\n",
       "1051                 ΓÇÖ|NNC\n",
       "1052              hiling|NNC\n",
       "1059             inuming|NNC\n",
       "1070           paliwanag|NNC\n",
       "1071              taguan|NNC\n",
       "1072              gulang|NNC\n",
       "1075          bulawbulaw|NNC\n",
       "1078                bato|NNC\n",
       "1082             sapatos|NNC\n",
       "1083                Ewan|NNC\n",
       "1084            sisidlan|NNC\n",
       "1089                bote|NNC\n",
       "1092             Larawan|NNC\n",
       "1103                lolo|NNC\n",
       "1107                utos|NNC\n",
       "1108       pagkakaibigan|NNC\n",
       "1116              ngipin|NNC\n",
       "1124              titser|NNC\n",
       "1125               tubig|NNC\n",
       "1128               anino|NNC\n",
       "1138                Lolo|NNC\n",
       "1145              paraan|NNC\n",
       "1150           puluputan|NNC\n",
       "1151             pasukan|NNC\n",
       "1157                loob|NNC\n",
       "1162               buwan|NNC\n",
       "1173                pusa|NNC\n",
       "1176            biskuwit|NNC\n",
       "1182                ikot|NNC\n",
       "1184             damuhan|NNC\n",
       "1188             hapunan|NNC\n",
       "1191             palitan|NNC\n",
       "1198            pangisda|NNC\n",
       "1201          pangyayari|NNC\n",
       "1202               palay|NNC\n",
       "1209               sagot|NNC\n",
       "1211               klase|NNC\n",
       "1214          pagkasakim|NNC\n",
       "1218               duyan|NNC\n",
       "1220                ulan|NNC\n",
       "1233                 ari|NNC\n",
       "1238             bathala|NNC\n",
       "1245               Sigaw|NNC\n",
       "1249             pagtaas|NNC\n",
       "1250            panganay|NNC\n",
       "1255                Lani|NNC\n",
       "1258                dami|NNC\n",
       "1261                puno|NNC\n",
       "1268           halimbawa|NNC\n",
       "1271                tuwa|NNC\n",
       "1272             hamapas|NNC\n",
       "1273             sumbong|NNC\n",
       "1275            atensyon|NNC\n",
       "1284               alala|NNC\n",
       "1292               sanga|NNC\n",
       "1294              pataas|NNC\n",
       "1298              tumpok|NNC\n",
       "1299               bukal|NNC\n",
       "1313            bulaklak|NNC\n",
       "1317                taya|NNC\n",
       "1324                 Mag|NNC\n",
       "1325                unan|NNC\n",
       "1328              bangka|NNC\n",
       "1331                 Ins|NNC\n",
       "1339           mananayaw|NNC\n",
       "1341         pamimingwit|NNC\n",
       "1344          pakiramdam|NNC\n",
       "1352            paggamit|NNC\n",
       "1354               Itlog|NNC\n",
       "1363              langoy|NNC\n",
       "1364             bakuran|NNC\n",
       "1367                  yo|NNC\n",
       "1378               bilog|NNC\n",
       "1383              kislap|NNC\n",
       "1392              eksena|NNC\n",
       "1397               bunot|NNC\n",
       "1398              anakan|NNC\n",
       "1404            pakialam|NNC\n",
       "1414                pala|NNC\n",
       "1416           direksyon|NNC\n",
       "1423           kasiyahan|NNC\n",
       "1425             tawanan|NNC\n",
       "1429             iskuter|NNC\n",
       "1430                alay|NNC\n",
       "1435            kalayuan|NNC\n",
       "1439         imprentahan|NNC\n",
       "1440               nanay|NNC\n",
       "1442               ngiti|NNC\n",
       "1443               sisiw|NNC\n",
       "1445               bilis|NNC\n",
       "1449                 aso|NNC\n",
       "1454                Kwak|NNC\n",
       "1457               porma|NNC\n",
       "1462             retrato|NNC\n",
       "1463               habol|NNC\n",
       "1471                asim|NNC\n",
       "1475              kuwago|NNC\n",
       "1477             hugasan|NNC\n",
       "1479                 ulo|NNC\n",
       "1483        dalampasigan|NNC\n",
       "1485               rhino|NNC\n",
       "1486               turan|NNC\n",
       "1500                Luna|NNC\n",
       "1502              tutubi|NNC\n",
       "1509               libro|NNC\n",
       "1510          kalangitan|NNC\n",
       "1515          magkakampi|NNC\n",
       "1518              saging|NNC\n",
       "1524          karamdaman|NNC\n",
       "1526              hihihi|NNC\n",
       "1528            katwiran|NNC\n",
       "1530            kaarawan|NNC\n",
       "1534               dahon|NNC\n",
       "1548          pagsasalin|NNC\n",
       "1554             palayan|NNC\n",
       "1562                ibon|NNC\n",
       "1564            pagtagpi|NNC\n",
       "1567                  aw|NNC\n",
       "1568           mamumutol|NNC\n",
       "1572             habagat|NNC\n",
       "1577             didilig|NNC\n",
       "1587              bundok|NNC\n",
       "1591           kaganapan|NNC\n",
       "1597                poso|NNC\n",
       "1599                dyan|NNC\n",
       "1601              kausap|NNC\n",
       "1606                sama|NNC\n",
       "1607             kumulog|NNC\n",
       "1621               palad|NNC\n",
       "1625               imbak|NNC\n",
       "1638            dingding|NNC\n",
       "1640              kwarto|NNC\n",
       "1646                  Uy|NNC\n",
       "1649                 bag|NNC\n",
       "1653               pasok|NNC\n",
       "1660               uulan|NNC\n",
       "1663            Pasensya|NNC\n",
       "1680               uusap|NNC\n",
       "1687                oras|NNC\n",
       "1691                tupi|NNC\n",
       "1692                dulo|NNC\n",
       "1694                Luha|NNC\n",
       "1696                tora|NNC\n",
       "1716                gawi|NNC\n",
       "1720             kabinet|NNC\n",
       "1724                kesa|NNC\n",
       "1728            nilalang|NNC\n",
       "1732               ugali|NNC\n",
       "1742              bahagi|NNC\n",
       "1749                 ina|NNC\n",
       "1753              tulong|NNC\n",
       "1755                araw|NNC\n",
       "1758              manilo|NNC\n",
       "1759             taniman|NNC\n",
       "1763           ikabubuti|NNC\n",
       "1765              ilahas|NNC\n",
       "1767               tatay|NNC\n",
       "1770                isip|NNC\n",
       "1779             trabaho|NNC\n",
       "1780            baluktot|NNC\n",
       "1782            buhangin|NNC\n",
       "1784            elepante|NNC\n",
       "1785                kuya|NNC\n",
       "1786             pabango|NNC\n",
       "1789           talahiban|NNC\n",
       "1792              unggoy|NNC\n",
       "1794               hinga|NNC\n",
       "1800             palabas|NNC\n",
       "1801           balkonahe|NNC\n",
       "1805                yaya|NNC\n",
       "1806               kulog|NNC\n",
       "1815              buntot|NNC\n",
       "1819               balat|NNC\n",
       "1821                Bato|NNC\n",
       "1823            magulang|NNC\n",
       "1824               sitaw|NNC\n",
       "1830                Lisa|NNC\n",
       "1832          lalanguyan|NNC\n",
       "1833              bangin|NNC\n",
       "1834              daanan|NNC\n",
       "1835             korales|NNC\n",
       "1844               aklat|NNC\n",
       "1849           pakatapos|NNC\n",
       "1851              karton|NNC\n",
       "1852              aralan|NNC\n",
       "1856             bituwin|NNC\n",
       "1858              sapsap|NNC\n",
       "1862            problema|NNC\n",
       "1863                 Yan|NNC\n",
       "1866         publication|NNC\n",
       "1868               pagod|NNC\n",
       "1869                 nun|NNC\n",
       "1870              kuweba|NNC\n",
       "1876        kapitbahayan|NNC\n",
       "1885             kaklase|NNC\n",
       "1886                ilog|NNC\n",
       "1890             lambing|NNC\n",
       "1894             langgam|NNC\n",
       "1903             pasayan|NNC\n",
       "1906             tinapay|NNC\n",
       "1910               ilong|NNC\n",
       "1914                daga|NNC\n",
       "1917               kulay|NNC\n",
       "1919               sigaw|NNC\n",
       "1925               silid|NNC\n",
       "1933               hayop|NNC\n",
       "1963               hawak|NNC\n",
       "1964          paglalakad|NNC\n",
       "1967                 Ate|NNC\n",
       "1968             larawan|NNC\n",
       "1969                 ΓÇÿ|NNC\n",
       "1980              kuneho|NNC\n",
       "1981              tuktok|NNC\n",
       "1998        pagtatrabaho|NNC\n",
       "1999                wika|NNC\n",
       "2002               takot|NNC\n",
       "2014            Bulaklak|NNC\n",
       "2015             lampara|NNC\n",
       "2034                ulam|NNC\n",
       "2039             halaman|NNC\n",
       "2040             salawal|NNC\n",
       "2051             paglaki|NNC\n",
       "2053             pinggan|NNC\n",
       "2057           pagbagsak|NNC\n",
       "2066              bitbit|NNC\n",
       "2073           pagsasama|NNC\n",
       "2074           kasagutan|NNC\n",
       "2076              kabibe|NNC\n",
       "2078               silip|NNC\n",
       "2079             panahon|NNC\n",
       "2081                saya|NNC\n",
       "2092             managat|NNC\n",
       "2100              dahoon|NNC\n",
       "2102                aral|NNC\n",
       "2110            bulungan|NNC\n",
       "2115               labas|NNC\n",
       "2120             habulan|NNC\n",
       "2122               bunso|NNC\n",
       "2126               galaw|NNC\n",
       "2127          paghakbang|NNC\n",
       "2130            pasamano|NNC\n",
       "2131            Gumuguho|NNC\n",
       "2147               abala|NNC\n",
       "2149               laman|NNC\n",
       "2152          ilustrador|NNC\n",
       "2153              laruan|NNC\n",
       "2154          karpintero|NNC\n",
       "2163                apoy|NNC\n",
       "2168                labi|NNC\n",
       "2170              palaka|NNC\n",
       "2178              tabing|NNC\n",
       "2180               rolyo|NNC\n",
       "2184              sagana|NNC\n",
       "2194             kamusta|NNC\n",
       "2197                 Nay|NNC\n",
       "2199               lakas|NNC\n",
       "2202              agimat|NNC\n",
       "2208                bata|NNC\n",
       "2212                ihip|NNC\n",
       "2213               yakap|NNC\n",
       "2224            sitsirya|NNC\n",
       "2227               tigre|NNC\n",
       "2235               upuan|NNC\n",
       "2242               harap|NNC\n",
       "2245           panloloko|NNC\n",
       "2250               pugad|NNC\n",
       "2253             pananim|NNC\n",
       "2254            karakter|NNC\n",
       "2261                 ani|NNC\n",
       "2262            simbahan|NNC\n",
       "2263                  Ma|NNC\n",
       "2265              batuan|NNC\n",
       "2269               barko|NNC\n",
       "2277               sabon|NNC\n",
       "2282           matatanda|NNC\n",
       "2284                init|NNC\n",
       "2291               kanta|NNC\n",
       "2294               bukid|NNC\n",
       "2302                tsok|NNC\n",
       "2303         magkaibigan|NNC\n",
       "2309           katandaan|NNC\n",
       "2321           pagkauhaw|NNC\n",
       "2323               Gabay|NNC\n",
       "2329               hukay|NNC\n",
       "2332               oyayi|NNC\n",
       "2337               ingat|NNC\n",
       "2356               mukha|NNC\n",
       "2358               patay|NNC\n",
       "2363            pagbalik|NNC\n",
       "2366               laban|NNC\n",
       "2367                Ping|NNC\n",
       "2368               donut|NNC\n",
       "2370              singko|NNC\n",
       "2372                Iyan|NNC\n",
       "2376            pagputol|NNC\n",
       "2378               pinto|NNC\n",
       "2380               balik|NNC\n",
       "2381               bitag|NNC\n",
       "2385               malay|NNC\n",
       "2391         paghihintay|NNC\n",
       "2398              anyaya|NNC\n",
       "2411               Tatay|NNC\n",
       "2412             uumpisa|NNC\n",
       "2413                alok|NNC\n",
       "2418           Kamayanan|NNC\n",
       "2421              lalaki|NNC\n",
       "2423              pinsan|NNC\n",
       "2424                 Opo|NNC\n",
       "2425               hamog|NNC\n",
       "2426               plato|NNC\n",
       "2433            Pagpasok|NNC\n",
       "2443          eskwelahan|NNC\n",
       "2448           pagtulong|NNC\n",
       "2460               bulsa|NNC\n",
       "2471                pato|NNC\n",
       "2478             salamin|NNC\n",
       "2481                 upo|NNC\n",
       "2482                daan|NNC\n",
       "2489            kaibigan|NNC\n",
       "2492             kuwarto|NNC\n",
       "2494                papa|NNC\n",
       "2501                tuka|NNC\n",
       "2506               Nanay|NNC\n",
       "2507          magkapatid|NNC\n",
       "2515                huni|NNC\n",
       "2516             garapon|NNC\n",
       "2519              sarili|NNC\n",
       "2526               sakit|NNC\n",
       "2529               bahay|NNC\n",
       "2531               galit|NNC\n",
       "2539                 ama|NNC\n",
       "2553            kakambal|NNC\n",
       "2563        pagmamakaawa|NNC\n",
       "2568           kalamidad|NNC\n",
       "2570             tagpiin|NNC\n",
       "2575              kabayo|NNC\n",
       "2580                taka|NNC\n",
       "2586            pakiusap|NNC\n",
       "2588              langit|NNC\n",
       "2591                lawa|NNC\n",
       "2593                Lola|NNC\n",
       "2595                anak|NNC\n",
       "2602                talo|NNC\n",
       "2605             siyudad|NNC\n",
       "2627                miss|NNC\n",
       "2628             pahayag|NNC\n",
       "2645            pagulong|NNC\n",
       "2648             pampang|NNC\n",
       "2650              hantik|NNC\n",
       "2651                asan|NNC\n",
       "2654             tilapya|NNC\n",
       "2656               pauwi|NNC\n",
       "2667              Tulong|NNC\n",
       "2672                lola|NNC\n",
       "2681               kamay|NNC\n",
       "2685                baka|NNC\n",
       "2694               Titay|NNC\n",
       "2696                isda|NNC\n",
       "2699           kagubatan|NNC\n",
       "2703               aaral|NNC\n",
       "2711             okasyon|NNC\n",
       "2714               gulay|NNC\n",
       "2715               liksi|NNC\n",
       "2723                 ΓÇ¥|NNC\n",
       "2731               Hello|NNC\n",
       "2732                mata|NNC\n",
       "2736          alalahanin|NNC\n",
       "2743             Balabaw|NNC\n",
       "2751               butas|NNC\n",
       "2752                 uod|NNC\n",
       "2759               damit|NNC\n",
       "2769              paslit|NNC\n",
       "2770               boses|NNC\n",
       "2775               batis|NNC\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "print(vocab_df.loc[ vocab_df['postag']==\"NNC\" ]['tokens'].shape)\n",
    "vocab_df.loc[ vocab_df['postag']==\"NNC\" ]['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the vocabulary and the sentences into the Organized_Text_data folder in the form of csv's\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#vocab_df.to_csv(\"./Organized_Text_data/vocabulary.csv\")\n",
    "\n",
    "sentenceInp = open(\"./textData_postagged/textAll_tagged_final.txt\", 'r', encoding='utf-8')\n",
    "sentenceDF = pd.DataFrame(sentenceInp.readlines(), columns=['sentence'])\n",
    "sentenceDF.to_csv(\"./Organized_Text_data/sentences.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The machine learning part after preprocessing\n",
    "\n",
    "@inproceedings{kuran2024hybrid,\n",
    "  title={A HYBRID BILSTM-CRF MODEL WITH BERT EMBEDDINGS FOR NAMED ENTITY RECOGNITION ON CONFIDENTIAL SYNTHETIC DATA},\n",
    "  author={Kuran, Emre Can and Elen, Abdullah and Kuran, Umut},\n",
    "  booktitle={V. INTERNATIONAL SCIENCE AND INNOVATION CONGRESS (INSI 2024) PROCEEDINGS BOOK},\n",
    "  pages={16}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pre-training the ELMO model so I have the weights needed (source: https://huggingface.co/datasets/linkanjarad/Wikitext-TL39/tree/main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert parquet to text\n",
    "import pandas as pd\n",
    "import fastparquet\n",
    "import pyarrow\n",
    "import numpy as np\n",
    "\n",
    "wikiData = pd.read_parquet('./Pre-training/train.parquet')\n",
    "wikiData.to_csv('./Pre-training/train.txt', header=None, index=None, sep='\\n', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208798244"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean up the pre-training data\n",
    "import re\n",
    "\n",
    "readTrain = open('./Pre-training/train.txt', 'r', encoding='utf-8')\n",
    "writeThis = re.sub(r\"= [a-zA-Z ]+ =\", '',readTrain.read())\n",
    "writeTrain = open('./Pre-training/train_1.txt', 'w', encoding='utf-8')\n",
    "writeTrain.write(writeThis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "readTrain = open('./Pre-training/train.txt', 'r', encoding='utf-8')\n",
    "allTopics = re.findall(r\"= [a-zA-Z ]+ =\", readTrain.read())\n",
    "allTopicsFinal = []\n",
    "for i in allTopics:\n",
    "    allTopicsFinal.append(i[2:-2])\n",
    "\n",
    "pd.DataFrame(allTopicsFinal, columns=['topics']).to_csv(\"./Organized_Text_data/vocabulary_wiki_tl39.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Length of the intersection of each dataset=======================\n",
      "filwordnet_preTrain: 1651\n",
      "filwordnet_childrensBook: 364\n",
      "preTrain_childrensBook: 292\n",
      "AllDatasets: 149\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compare vocabularies\n",
    "import pandas as pd\n",
    "\n",
    "filwordnet_lemmas = pd.read_csv(\"./Organized_Text_data/filWordNetLemmas.csv\")['lemma'].to_frame()\n",
    "preTrain_topics = pd.read_csv(\"./Organized_Text_data/vocabulary_wiki_tl39.csv\")['topics'].to_frame()\n",
    "childrensBook_vocabulary = pd.read_csv(\"./Organized_Text_data/vocabulary.csv\")['lemma'].to_frame()\n",
    "\n",
    "filwordnet_lemmas.columns = ['vocabulary']\n",
    "preTrain_topics.columns = ['vocabulary']\n",
    "childrensBook_vocabulary.columns = ['vocabulary']\n",
    "\n",
    "filwordnet_lemmas['vocabulary'] = filwordnet_lemmas['vocabulary'].str.lower()\n",
    "preTrain_topics['vocabulary'] = preTrain_topics['vocabulary'].str.lower()\n",
    "childrensBook_vocabulary['vocabulary'] = childrensBook_vocabulary['vocabulary'].str.lower()\n",
    "\n",
    "#print(f\"{filwordnet_lemmas.info()} {preTrain_vocabulary.info()} {childrensBook_vocabulary.info()}\")\n",
    "\n",
    "filwordnet_preTrain = filwordnet_lemmas.merge(preTrain_topics, how='inner', on=['vocabulary']).drop_duplicates()\n",
    "filwordnet_childrensBook = filwordnet_lemmas.merge(childrensBook_vocabulary, how='inner', on=['vocabulary']).drop_duplicates()\n",
    "preTrain_childrensBook = preTrain_topics.merge(childrensBook_vocabulary, how='inner', on=['vocabulary']).drop_duplicates()\n",
    "\n",
    "allmerge = filwordnet_preTrain.merge(preTrain_childrensBook, how='inner', on=['vocabulary']).drop_duplicates()\n",
    "\n",
    "print(f'''\n",
    "Length of the intersection of each dataset=======================\n",
    "filwordnet_preTrain: {filwordnet_preTrain.shape[0]}\n",
    "filwordnet_childrensBook: {filwordnet_childrensBook.shape[0]}\n",
    "preTrain_childrensBook: {preTrain_childrensBook.shape[0]}\n",
    "AllDatasets: {allmerge.shape[0]}\n",
    "\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic finder sa wiki\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "\n",
    "topicList = pd.concat((filwordnet_preTrain, preTrain_childrensBook)).drop_duplicates()['vocabulary'].str.lower().tolist()\n",
    "topicSet = set(topicList)\n",
    "\n",
    "readTrain = open('./Pre-training/train.txt', 'r', encoding='utf-8')\n",
    "readTrainText = readTrain.readlines()\n",
    "readTrainText\n",
    "\n",
    "topicDict_withExamples = {}\n",
    "currentTopic = \"DELETE_THIS_KEY\"\n",
    "\n",
    "for line in readTrainText:\n",
    "    #print(line, currentTopic)\n",
    "    if(line[0] == '='):\n",
    "        # check if the thing we're looking at is at this list\n",
    "        toCheck = line[2:-3]\n",
    "        if toCheck.lower() in topicSet:\n",
    "            currentTopic = toCheck\n",
    "            #print(currentTopic)\n",
    "            topicDict_withExamples[currentTopic] = []\n",
    "        else:\n",
    "            currentTopic = \"DELETE_THIS_KEY\"\n",
    "    else:\n",
    "        if currentTopic != \"DELETE_THIS_KEY\":\n",
    "            topicDict_withExamples[currentTopic].append(line)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "with open(\"./Organized_Text_data/topic_withExamples.json\", \"w\") as outfile: \n",
    "    json.dump(topicDict_withExamples, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all sentences in the common topic thing into a single text file\n",
    "import json\n",
    "import math as m\n",
    "\n",
    "commonTopics = open(\"./Organized_Text_data/topic_withExamples.json\")\n",
    "data = json.load(commonTopics)\n",
    "\n",
    "keyChunks = []\n",
    "chunk_count = 4\n",
    "keylist = list(data.keys())\n",
    "\n",
    "chunk_size = m.ceil(len(keylist)/chunk_count)\n",
    "\n",
    "for i in range(chunk_count):\n",
    "    keyChunks.append(keylist[(chunk_size*i): (chunk_size*(i+1))])\n",
    "\n",
    "chunk_ind = 1\n",
    "for chunk in keyChunks:\n",
    "    sentenceList = []\n",
    "\n",
    "    for key in chunk:\n",
    "        for sentence in data[key]:\n",
    "            sentenceList.append(sentence)\n",
    "\n",
    "    sentenceList_file = open(f\"./Pre-training/train_common_lite_{chunk_ind}.txt\", \"w\", encoding='utf-8')\n",
    "    sentenceList_file.writelines(sentenceList)\n",
    "    sentenceList_file.close()\n",
    "    chunk_ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the text files into one\n",
    "\n",
    "preTrainCorpus = open(\"./Pre-training/train_common_postagged.txt\", 'w', encoding='utf-8')\n",
    "\n",
    "for i in range(1,4+1):\n",
    "    f = open(f\"./Pre-training/train_1_common_lite_{i}.txt\", 'r', encoding='utf-16')\n",
    "    preTrainCorpus.write(f.read())\n",
    "    f.close()\n",
    "\n",
    "preTrainCorpus.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5640685"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format the postag file\n",
    "# organize it properly\n",
    "import re\n",
    "\n",
    "tagged_Text = open(\"./Pre-training/train_common_postagged.txt\", 'r', encoding=\"utf-8\")\n",
    "\n",
    "allText = tagged_Text.read()\n",
    "#print(allText)\n",
    "allText = re.sub(r'\\|PMP \\\"\\|PMS\\n', '|PMP  \\n\\\"|PMS ', allText)\n",
    "allText = re.sub(r'\\|PMQ \\\"\\|PMS\\n', '|PMQ  \\n\\\"|PMS ', allText)\n",
    "allText = re.sub(r'\\|PME \\\"\\|PMS\\n', '|PME  \\n\\\"|PMS ', allText)\n",
    "allText = re.sub(r'\\|PMS \\\"\\|PMS\\n', '|PMS  \\n\\\"|PMS ', allText)\n",
    "allText = re.sub(r'\\|PMC \\\"\\|PMS\\n', '|PMC  \\n\\\"|PMS ', allText)\n",
    "allText = re.sub(r'\\|PMSC \\\"\\|PMS\\n','|PMSC \\n\\\"|PMS ', allText)\n",
    "\n",
    "final_Text = open(\"./Pre-training/train_1_common_postagged.txt\", 'w')\n",
    "final_Text.write(allText)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 16483\n",
      "Test: 4121\n"
     ]
    }
   ],
   "source": [
    "# split the data 80-20\n",
    "import pandas as pd\n",
    "\n",
    "trainingData_common_file = open(\"./Pre-training/train_1_common_postagged.txt\", 'r', encoding='utf-8')\n",
    "\n",
    "trainingData_common = pd.DataFrame(trainingData_common_file.readlines(), columns=['sentences'])\n",
    "\n",
    "trainingData_common_test = trainingData_common.sample(frac=0.2, random_state=6423)\n",
    "\n",
    "# get the rows that are in trainingData_common but not it the trainingData_common_test\n",
    "allddd = pd.DataFrame()\n",
    "allddd[\"dd\"] = trainingData_common\n",
    "allddd[\"qq\"] = trainingData_common_test\n",
    "allddd[\"final\"] = allddd[\"dd\"] * (allddd[\"dd\"] != allddd[\"qq\"])\n",
    "ffiii = allddd['final'].values.tolist()\n",
    "\n",
    "pop_index = 0\n",
    "while pop_index < len(ffiii):\n",
    "    if ffiii[pop_index] == '':\n",
    "        ffiii.pop(pop_index)\n",
    "    else:\n",
    "        pop_index+=1\n",
    "\n",
    "trainingData_common_train = pd.DataFrame(ffiii, columns=['sentences'])\n",
    "print(f\"Train: {trainingData_common_train.shape[0]}\\nTest: {trainingData_common_test.shape[0]}\")\n",
    "\n",
    "\n",
    "\n",
    "tr = open(\"./Pre-training/trainingData_ELMO.txt\",'w', encoding='utf-8')\n",
    "tr.writelines(i[0] for i in trainingData_common_train.values.tolist())\n",
    "tr.close()\n",
    "\n",
    "te = open(\"./Pre-training/testData_ELMO.txt\",'w', encoding='utf-8')\n",
    "te.writelines(i[0] for i in trainingData_common_test.values.tolist())\n",
    "te.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELMO -> BiLSTM -> CRF\n",
    "\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "import torch\n",
    "\n",
    "# Load ELMo model\n",
    "options_file = \"https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
    "weight_file = \"https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
    "elmo = Elmo(options_file, weight_file, num_output_representations=1, dropout=0)\n",
    "\n",
    "# Define a custom component for ELMo embeddings\n",
    "@Language.component(\"elmo_embedder\")\n",
    "def elmo_embedder(doc):\n",
    "    # Convert SpaCy tokens to ELMo character IDs\n",
    "    token_ids = batch_to_ids([[token.text for token in doc]])\n",
    "    \n",
    "    # Get ELMo embeddings (shape: [batch_size, max_length, 1024])\n",
    "    embeddings = elmo(token_ids)[\"elmo_representations\"][0]\n",
    "    \n",
    "    # Store ELMo embeddings in Doc object\n",
    "    doc._.elmo_embeddings = embeddings.squeeze(0)  # Remove batch dimension\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
